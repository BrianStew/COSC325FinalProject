{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2953a83d",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537711a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ba2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bafc395",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e07295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text author\n",
      "0  id26305  this process  however  afforded me no means of...    EAP\n",
      "1  id17569  it never once occurred to me that the fumbling...    HPL\n",
      "2  id11008  in his left hand was a gold snuff box  from wh...    EAP\n",
      "3  id27763  how lovely is spring as we looked from windsor...    MWS\n",
      "4  id12958  finding nothing else  not even gold  the super...    HPL\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Lowercase and remove punctuation\n",
    "to_remove = ['.', ',', '?', '!', ':', ';']\n",
    "replacement = \" \"\n",
    "\n",
    "pattern = \"|\".join(map(re.escape, to_remove))\n",
    "df[\"text\"] = df[\"text\"].str.replace(pattern, replacement, regex=True)\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f6ced5",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3f8aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'process', 'however', 'afforded', 'me', 'no', 'means', 'of', 'ascertaining', 'the', 'dimensions', 'of', 'my', 'dungeon', 'as', 'i', 'might', 'make', 'its', 'circuit', 'and', 'return', 'to', 'the', 'point', 'whence', 'i', 'set', 'out', 'without', 'being', 'aware', 'of', 'the', 'fact', 'so', 'perfectly', 'uniform', 'seemed', 'the', 'wall'], ['it', 'never', 'once', 'occurred', 'to', 'me', 'that', 'the', 'fumbling', 'might', 'be', 'a', 'mere', 'mistake']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "data = []\n",
    "\n",
    "# Tokenize the text data\n",
    "for i in range(len(df)):\n",
    "    temp = []\n",
    "    for j in range(len(df['text'][i].split())):\n",
    "        temp.append(df['text'][i].split()[j])\n",
    "    data.append(temp)\n",
    "\n",
    "print(data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06970b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "model1 = gensim.models.Word2Vec(data, min_count=1,vector_size=100, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c176dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between chicken and butter:  85.88%\n"
     ]
    }
   ],
   "source": [
    "word1 = 'chicken'\n",
    "word2 = 'butter'\n",
    "\n",
    "word_sim = model1.wv.similarity(word1, word2) * 100\n",
    "word_sim = word_sim\n",
    "\n",
    "print(f\"Similarity between {word1} and {word2}: {word_sim : .2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
