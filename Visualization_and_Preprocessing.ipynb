{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82200e10",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01cb6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a04125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4c46e",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0487b31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest 10 word counts from EAP were [267, 256, 169, 164, 157, 149, 148, 148, 140, 137].\n",
      "The highest 10 word counts from HPL were [147, 134, 117, 113, 113, 108, 102, 102, 100, 99].\n",
      "The highest 10 word counts from MWS were [861, 594, 445, 377, 335, 191, 190, 186, 186, 181].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP_text_length</th>\n",
       "      <th>HPL_text_length</th>\n",
       "      <th>MWS_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7900.000000</td>\n",
       "      <td>5635.000000</td>\n",
       "      <td>6044.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.442405</td>\n",
       "      <td>27.799645</td>\n",
       "      <td>27.417273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.567706</td>\n",
       "      <td>14.123252</td>\n",
       "      <td>23.134440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>267.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>861.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EAP_text_length  HPL_text_length  MWS_text_length\n",
       "count      7900.000000      5635.000000      6044.000000\n",
       "mean         25.442405        27.799645        27.417273\n",
       "std          18.567706        14.123252        23.134440\n",
       "min           2.000000         4.000000         2.000000\n",
       "25%          12.000000        18.000000        15.000000\n",
       "50%          21.000000        26.000000        23.000000\n",
       "75%          33.000000        35.000000        34.000000\n",
       "max         267.000000       147.000000       861.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_length'] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "author_names = df['author'].unique()\n",
    "authors_df_list = []\n",
    "word_summary = []\n",
    "for author in author_names:\n",
    "    author_df = df[df['author'] == author].rename(columns={'text_length' : f\"{author}_text_length\"})\n",
    "    top_ten_word_counts = heapq.nlargest(10, author_df[f\"{author}_text_length\"])\n",
    "    print(f\"The highest 10 word counts from {author} were {top_ten_word_counts}.\")\n",
    "    authors_df_list.append(author_df)\n",
    "    word_summary.append(author_df[f\"{author}_text_length\"].describe())\n",
    "word_summary_df = pd.concat(word_summary, axis=1)\n",
    "word_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f2f194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAP had 2 texts with more than 200 words. \n",
      "HPL had 0 texts with more than 200 words. \n",
      "MWS had 5 texts with more than 200 words. \n"
     ]
    }
   ],
   "source": [
    "max_word_count = 200\n",
    "for i, author in enumerate(author_names):\n",
    "    initial_count = len(authors_df_list[i])\n",
    "    authors_df_list[i] = authors_df_list[i][authors_df_list[i][f'{author}_text_length'] <= max_word_count]\n",
    "    print(f\"{author} had {initial_count - len(authors_df_list[i])} texts with more than {max_word_count} words. \")\n",
    "df = df[df['text_length'] <= max_word_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995f05d",
   "metadata": {},
   "source": [
    "It is important to note that most of these samples fall within the range of 200. This means that we should remove the 9 entries (2 from EAP and 7 from MWS) that have more than 200 entries and consider them outliers. While a more strict boundary may be chosen, one must remember the importance of not \"overfitting by hand\". Choosing a loose boundary that only gets rid of large outlier helps improve generalizability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746e4723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGiCAYAAADNzj2mAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPXhJREFUeJzt3X1wlPW9///XJpgFNDckkGwiERKsd9FgqhCjSOCYKuiJzQgoFBBbxNYEq/AttWQ0SrDiqKeHsYQ4tVR7BIrkKGg5U3oAa6gSAiJMGrRRMAI2JCq6CQTZhU1+f/jLnl2yQG5297rC9XzM7LjX9Xmz+95xs/vez/W5sbW3t7cLAADARCKMTgAAAOB0FCgAAMB0KFAAAIDpUKAAAADToUABAACmQ4ECAABMhwIFAACYDgUKAAAwHQoUAABgOhQoAADAdLpVoCxZskSjRo1SdHS0EhMTVVBQoLq6Or+YEydOqKioSAkJCbrooos0adIkNTU1+cUcPHhQd9xxhwYOHKjExEQtWLBAp06d6v2rAQAA54VuFSiVlZUqKirS9u3btWnTJp08eVK33nqrWltbvTHz5s3Tn//8Z1VUVKiyslINDQ266667vO0ej0d33HGH3G63tm3bpj/+8Y965ZVXVFJSErxXBQAA+jRbbzYL/PLLL5WYmKjKykqNHTtWzc3NGjJkiFavXq3JkydLkv75z3/qyiuvVFVVlW644Qb95S9/0b//+7+roaFBSUlJkqQXX3xRjz76qL788ktFRUUF55UBAIA+q19v/nFzc7MkKT4+XpK0a9cunTx5Unl5ed6YK664Qpdccom3QKmqqtI111zjLU4k6bbbbtODDz6ovXv3Kisrq9PzuFwuuVwu73FbW5u+/vprJSQkyGaz9eYlAACAMGlvb9fRo0eVkpKiiIizX8TpcYHS1tamRx55RDfddJOuvvpqSVJjY6OioqIUFxfnF5uUlKTGxkZvjG9x0tHe0RbIkiVLtGjRop6mCgAATOTQoUMaOnToWWN6XKAUFRWptrZW7777bk8fossWLlyo+fPne4+bm5t1ySWX6NChQ4qJiQn58wMAgN5raWlRamqqoqOjzxnbowJl7ty52rBhg7Zu3epXATkcDrndbjmdTr9elKamJjkcDm/Mjh07/B6vY5ZPR8zp7Ha77HZ7p/MxMTEUKAAA9DFdGZ7RrVk87e3tmjt3rtatW6e3335baWlpfu3XXXedLrjgAm3ZssV7rq6uTgcPHlROTo4kKScnR//4xz/0xRdfeGM2bdqkmJgYXXXVVd1JBwAAnKe61YNSVFSk1atX680331R0dLR3zEhsbKwGDBig2NhYzZ49W/Pnz1d8fLxiYmL00EMPKScnRzfccIMk6dZbb9VVV12lmTNn6tlnn1VjY6Mee+wxFRUVBewlAQAA1tOtacZn6pJ5+eWXdd9990n6bqG2//f//p/+9Kc/yeVy6bbbbtPy5cv9Lt8cOHBADz74oN555x1deOGFmjVrlp555hn169e1eqmlpUWxsbFqbm7mEg8AAH1Ed76/e7UOilEoUAAA6Hu68/3NXjwAAMB0KFAAAIDpUKAAAADToUABAACm06u9eAAAOJ95PB7V1NToyJEjSkhIUGZmpiIjI41OyxIoUAAACKCyslJlZWV++8Q5HA4VFRUpNzfXwMysgQIFAIDTVFZWqqSkRDk5OZo2bZrsdrtcLpeqq6tVUlKi0tJSipQQYx0UAAB8eDweTZs2TbGxsXI6nd794iQpKSlJcXFxamlp0erVq7nc002sgwIAQA/V1NSosbFRdXV1GjFihMrLy7Vx40aVl5drxIgRqqur0+HDh1VTU2N0quc1ChQAAHx8+eWXkqTs7Gw9/fTTysjI0MCBA5WRkaGnn35a2dnZfnEIDQoUAAB8OJ1OSdLYsWMVEeH/NRkREaGbb77ZLw6hQYECAICPuLg4SdLWrVvV1tbm19bW1qa///3vfnEIDQoUAAB8DBkyRJK0Y8cOFRcXq7a2VsePH1dtba2Ki4u1Y8cOvziEBtOMAQDwkZmZKYfDodjYWO3fv1+FhYXeNofDocsuu0wtLS3KzMw0MMvzHz0oAAD4iIyMVFFRkerq6vymGEvyzu4pLCxkinGIUaAAAHCavXv3SlLAQbK+7QgdLvEAAODD7XaroqJCgwYN0tq1a/Xhhx969+K56qqrdPfdd6uiokL333+/oqKijE73vEUPCgAAPtavXy+Px6P7779fdrtdWVlZysvLU1ZWlux2u2bPni2Px6P169cbnep5jQIFAAAfDQ0NkqQbb7wxYHvH+Y44hAYFCgAAPlJSUiRJ27ZtC9jecb4jDqFBgQIAgI+CggJFRkbq97//vU6dOuXXdurUKa1YsUKRkZEqKCgwJkGLoEABAMBHVFSUpkyZom+++UaTJk3SW2+9pa+++kpvvfWWJk2apG+++UZTpkxhgGyIMYsHAIDTdCzOtnbtWj3//PPe85GRkZo6darf4m0IDXpQAAAIICMjo9Ny9oMHD1ZGRoZBGVkLBQoAAKeprKxUSUmJRowYofLycm3cuFHl5eUaMWKESkpKVFlZaXSK5z1be3t7u9FJdFdLS4tiY2PV3NysmJgYo9MBAJxHPB6Ppk2bpvT0dD399NN+q8m2tbWpuLhY9fX1Wr16Ncvdd1N3vr/pQQEAwEdNTY0aGxs1c+bMgEvdz5gxQ4cPH1ZNTY1BGVoDBQoAAD6OHDkiSUpLSwvYnp6e7heH0GAWDwAAPhISEiRJ9fX1uuKKK1RTU+PdiyczM1OffvqpXxxCgwIFAAAfmZmZcjgcWrp0qZxOp5qamrxtSUlJiouLU3JysjIzMw3M8vzHJR4AAHxERkZq3Lhxqqurk9vt1oIFC/TGG29owYIFcrvdqqurU25uLgNkQ4xZPAAA+OiYxdPxPdPY2OhtS05OVkxMjFpaWpjF0wPd+f7mEg8AAD46ZvE88cQTAcegfPTRRyosLFRNTY2ysrKMTve81e1LPFu3blV+fr5SUlJks9m0fv16v3abzRbw9txzz3ljhg8f3qn9mWee6fWLAQCgt3xn8URGRiorK0t5eXnKyspSZGQks3jCpNsFSmtrq0aOHKmysrKA7YcPH/a7/eEPf5DNZtOkSZP84kpLS/3iHnrooZ69AgAAgsh3Fk8gzOIJj25f4pk4caImTpx4xnaHw+F3/Oabb2r8+PHeirNDdHR0p1gAAIzWMYvn1VdfDbiS7MqVK5nFEwYhncXT1NSk//mf/9Hs2bM7tT3zzDNKSEhQVlaWnnvuOZ06dSqUqQAA0CWRkZEqKipSVVWViouLVVtbq+PHj6u2tlbFxcWqqqpSYWEhA2RDLKSDZP/4xz8qOjpad911l9/5n//85/r+97+v+Ph4bdu2TQsXLtThw4f1m9/8JuDjuFwuuVwu73FLS0so0wYAWFxubq5KS0tVVlamwsJC7/nk5GSVlpYqNzfXwOysoVfTjG02m9atW6eCgoKA7VdccYV+8IMf6Le//e1ZH+cPf/iDfvrTn+rYsWOy2+2d2p988kktWrSo03mmGQMAQsnj8XSaxUPPSc+ZYprx3//+d9XV1em11147Z2x2drZOnTqlzz77TJdffnmn9oULF2r+/Pne45aWFqWmpgY1XwAATtcxiwfhF7ICZcWKFbruuus0cuTIc8bu2bNHERERSkxMDNhut9sD9qwAAIDzU7cLlGPHjmnfvn3e4/r6eu3Zs0fx8fG65JJLJH3Xw1FRUaH/+I//6PTvq6qqVF1drfHjxys6OlpVVVWaN2+eZsyYoUGDBvXipQAAgPNFtwuU999/X+PHj/ced1x6mTVrll555RVJ0po1a9Te3q5p06Z1+vd2u11r1qzRk08+KZfLpbS0NM2bN8/vEg4AALA29uIBAABhYYpBsjA/RqcDAMyKAsWiKisrVVZW5rdLp8PhUFFREfP7AQCGC+lKsjCnyspKlZSUKD09XeXl5dq4caPKy8uVnp6ukpISVVZWGp0iAMDiGINiMR6PR9OmTVN6enrAPSaKi4tVX1+v1atXc7kHABBU3fn+pgfFYmpqatTY2KiZM2f6FSeSFBERoRkzZujw4cOqqakxKEMAAChQLOfIkSOSpLS0tIDtHbtOd8QBAGAEChSLSUhIkPTdAnuBfPrpp35xAAAYgQLFYjIzM+VwOPTqq6+qra3Nr62trU0rV65UcnKyMjMzDcoQAACmGVtOZGSkioqKVFJSooULFyo7O1t2u10ul0vV1dXavn27SktLGSALADAUBYoF5ebm6p577lFFRYWqqqq85yMjI3XPPfewDgoAwHAUKBZUWVmp1157TTk5OZ16UF577TVlZGRQpAAADMU6KBbDOigAAKOwDgrOiHVQAAB9AQWKxbAOCgCgL6BAsRjWQQEA9AUUKBbDOigAgL6AAsViOtZBqaqqUnFxsWpra3X8+HHV1taquLhYVVVVKiwsZIAsAMBQzOKxqMrKSpWVlamxsdF7Ljk5WYWFhUwxBgCERHe+vylQLMzj8aimpkZHjhxRQkKCMjMz6TkBAIRMd76/WajNwiIjI5WVlWV0GgAAdMIYFAAAYDr0oFgYl3gAAGZFgWJRgQbJOhwOFRUVMUgWAGA4LvFYUGVlpUpKSpSenq7y8nJt3LhR5eXlSk9PV0lJiSorK41OEQBgcczisRg2CwQAGIXNAnFGbBYIAOgLKFAshs0CAQB9AQWKxbBZIACgL6BAsRg2CwQA9AUUKBbDZoEAgL6AWTwWxWaBAIBwY7NAdAkryQIAwonNAtElbBYIADArChQAAM6AnmbjdHuQ7NatW5Wfn6+UlBTZbDatX7/er/2+++6TzWbzu02YMMEv5uuvv9b06dMVExOjuLg4zZ49W8eOHevVCwEAIJgqKys1bdo0PfzwwyotLdXDDz+sadOmsR1ImHS7QGltbdXIkSNVVlZ2xpgJEybo8OHD3tuf/vQnv/bp06dr79692rRpkzZs2KCtW7fqgQce6H726BWPx6Pdu3dr8+bN2r17tzwej9EpAYApsGeZ8Xo1SNZms2ndunUqKCjwnrvvvvvkdDo79ax0+Oijj3TVVVdp586duv766yVJGzdu1O23367PP/9cKSkp53xeBsn2HrsZA0Bg7FkWOobvxfPOO+8oMTFRl19+uR588EG/ZdOrqqoUFxfnLU4kKS8vTxEREaqurg74eC6XSy0tLX439FzHL4O0tDRNnjxZd955pyZPnqy0tDR+GQCwPPYsM4egD5KdMGGC7rrrLqWlpWn//v0qLi7WxIkTVVVVpcjISDU2NioxMdE/iX79FB8f7/dr3teSJUu0aNGiYKdqSR6PR2VlZUpOTlZ1dbXfarIRERFKTk7W8uXLNWbMGH4ZALAk9iwzh6AXKFOnTvXev+aaa5SZmakRI0bonXfe0S233NKjx1y4cKHmz5/vPW5paVFqamqvc7Wijl8GkjRo0CDdf//9uvHGG7Vt2zb9/ve/V0NDgzeOKcgIN2ZMwAx89yzLyMjo1M6eZeER8mnG6enpGjx4sPbt26dbbrlFDodDX3zxhV/MqVOn9PXXX8vhcAR8DLvdLrvdHupULaGpqUmSFBcXp9dff139+n33FsjPz9fEiRN11113yel0euOAcGFcFMzCd8+yQGNQ2LMsPEK+F8/nn3+uI0eOKDk5WZKUk5Mjp9OpXbt2eWPefvtttbW1KTs7O9TpWN6HH34oSbrjjju8xUmHfv366fbbb/eLA8KBGRMwE/YsM4du96AcO3ZM+/bt8x7X19drz549io+PV3x8vBYtWqRJkybJ4XBo//79+uUvf6lLL71Ut912myTpyiuv1IQJEzRnzhy9+OKLOnnypObOnaupU6d2aQYPgqOurk5tbW2dfhl8/PHHBmYFK+oYF5WTk+P3azUjI0NPP/20iouLGReFsMvNzVVpaanKyspUWFjoPZ+cnKzS0lJ69cKg2wXK+++/r/Hjx3uPO8aGzJo1S+Xl5aqpqdEf//hHOZ1OpaSk6NZbb9XixYv9LtGsWrVKc+fO1S233KKIiAhNmjRJL7zwQhBeDs5l6NChkr77/1hcXKwZM2YoPT1dn376qVauXKn333/fLw4ItY5xUU888cQZZ0wUFhYyLgphl5ubqzFjxjAuyiDdLlDGjRunsy2d8te//vWcjxEfH6/Vq1d396kRBAUFBSovL1f//v21f/9+v18GDodDF154oU6cOOG3tg0QSsyYgJmxZ5lxQj4GBeYSFRWlKVOmqLW1VW63W3fffbceeeQR3X333XK5XGptbdWUKVMUFRVldKqwCN8ZE4EwYwKwJjYLtKCOXpOKigqtXbvWez4yMlJTp07161UBQo0ZEzAzpr4bp1dL3RuFpe6Dw+12a/369WpoaFBKSooKCgroOYEhOmbx5OTkdBoXVVVVxaBEGIKp78HXne9vChQAphDoyyA5OVmFhYV8GSDsfIvmmTNnKi0tTfX19Xr11VcpmnuBAgVAn0R3OsyAzQJDx/DNAgGgJzpmTOTl5SkrK4sPfxiCzQLNgUGyFsavVQDojKnv5kCBYlEM/gKAwNgs0By4xGNB7HsCAGfmO/W9ra3Nr42p7+FDgWIxp+97kpGRoYEDB3r3PcnJydHy5cvl8XiMThUADMFmgeZAgWIxDP4CgHPr2Czw008/VWFhoSZMmKDCwkLV19czxThMGINiMb6DvwINkmXwFwB8Jzc3Vzk5OSxoaRAKFIvpGNT1xhtv6K233uo0SDY/P98vDgCsKtBkgv/+7/9mMkGYcInHYjIzMxUXF6ff/e53SktL8xskm5aWppdeekmDBg1i8BcAS2MygfEoUCzMZrOpYyHh9vZ22Ww2730AsComE5gDBYrF1NTUyOl06oEHHgg4+GvOnDlyOp0MkgVgWUwmMAfGoFhMx+DXu+66S9OmTes0SNblcumll15ikCwAy2IlWXOgB8VifFdIDIQVEmEkj8ej3bt3a/Pmzdq9ezdd6DAEn5PmQA+KxXSskLh06VI1Nzd3msUTGxvLCokwBNsvwCx8V5INtJsxK8mGBz0oFhMZGalx48aprq5OLpdLCxYs0Lp167RgwQK5XC7V1dUpNzeXFRIRVsyYgJmwkqw52Nr74JSNlpYWxcbGqrm5WTExMUan06d4PB5NmzZNsbGxcjqdampq8rZ19KC0tLRo9erV/PEhLDrek+np6QF/rRYXF6u+vp73JMIuUK9ecnKyCgsL6dXroe58f3OJx2I6Rqc/8cQTuuKKKzoNkv3oo49UWFiompoaZWVlGZ0uLMD3PXmmGRO8J2GE3NxcjRkzptPnJIVyeFCgWIzv6PTIyMhOH/iMTke4MWMCZhbocxLhwRgUi2F0OsyG9ySAQChQLMZ3dHpbW5tfG6PTYQTekwACoUCxGEanw2x4TwIIhFk8FsXodJgN70ng/Ned728KFAvzeDyMToep8J4Ezm9MM0aXMDodZsN7EkAHChQAAM6AXj3jUKAAABAA+0MZi1k8FuZ2u7V27VotXbpUa9euldvtNjolADAF9ocyHoNkLWr58uWqqKjw284+MjJSU6ZMUWFhoYGZAYCx2B8qdLrz/d3tHpStW7cqPz9fKSkpstlsWr9+vbft5MmTevTRR3XNNdfowgsvVEpKiu699141NDT4Pcbw4cNls9n8bs8880x3U0EPLV++XGvWrFFMTIzfbsYxMTFas2aNli9fbnSKAGCYjv2hZs6cecb9oQ4fPqyamhqDMrSGbhcora2tGjlypMrKyjq1HT9+XB988IEef/xxffDBB3rjjTdUV1enO++8s1NsaWmpDh8+7L099NBDPXsF6Ba3262KigoNGjRIr7/+uvLz85WQkKD8/Hy9/vrrGjRokCoqKrjcA8Cy2B/KHLo9SHbixImaOHFiwLbY2Fht2rTJ79yyZcs0evRoHTx4UJdccon3fHR0tBwOR3efHr20fv16eTwe3X///bLZbNq9e7ff6PTZs2fr+eef1/r163X33XcbnS4AhJ3v/lAZGRmd2tkfKjxCPounublZNptNcXFxfuefeeYZLV68WJdccol+9KMfad68eerXj0lFodZxuc1ms2nq1KlqamrytiUlJenee+/1iwMAq/HdH2rx4sWqra31/pC7+uqr2R8qTEJaEZw4cUKPPvqopk2b5jcY5uc//7m+//3vKz4+Xtu2bdPChQt1+PBh/eY3vwn4OC6XSy6Xy3vc0tISyrTPaykpKZKkZ599tlNbU1OTnnvuOb84ALCajv2hHn/8cd1+++1+3z92u10ul0uLFy9mgGyIhaxAOXnypO6++261t7ervLzcr23+/Pne+5mZmYqKitJPf/pTLVmyRHa7vdNjLVmyRIsWLQpVqpaSn5+vZcuWSZLi4uKUlZWl/v3768SJE9q9e7ecTqc3DgCszGazdes8giskBUpHcXLgwAG9/fbb55xKlJ2drVOnTumzzz7T5Zdf3ql94cKFfkVNS0uLUlNTg563FdTW1nrvO51O/e1vfztj3KhRo8KVFgCYhsfjUVlZmXJycgJe4nn88ce1fPlyjRkzhl6UEAr6Qm0dxcknn3yizZs3d2kQ0Z49exQREaHExMSA7Xa7XTExMX439Mxf//rXoMYBwPnGd5rxBRdcoKysLOXl5SkrK0sXXHAB04zDpNs9KMeOHdO+ffu8x/X19dqzZ4/i4+OVnJysyZMn64MPPtCGDRvk8Xi8SwTHx8crKipKVVVVqq6u1vjx4xUdHa2qqirNmzdPM2bM0KBBg4L3yhDQsWPHJH1X9EVHR+urr77ytg0ePFhHjx6Vy+XyxgGA1TDN2By6XaC8//77Gj9+vPe449LLrFmz9OSTT+qtt96SJF177bV+/+5vf/ubxo0bJ7vdrjVr1ujJJ5+Uy+VSWlqa5s2b53cJB6HTce3U5XLpuuuu0+LFi5WWlqb6+nq9+uqr2rZtm18cAFgN04zNodsFyrhx43S21fHPtXL+97//fW3fvr27T4sg8f2D8ng8qqur02effSaXy+W37D1/eACsyneacaCl7plmHB4sPGIxvn9o1dXVqq6uPmccAFhJxzTjkpISFRcXa8aMGUpPT9enn36qlStXqqqqSqWlpQyQDTEKFIu56qqr/PZPOlscAFhVbm6uSktLVVZW5reBanJyskpLS5Wbm2tgdtZAgWIxQ4YM8d632Wx+l+R8j33jAMCKcnNzNWbMGNXU1PhtCULPSXhQoFjY6eOFzjV+CAg1j8fDlwEASRQoluM7LS4qKspv12LfY6bPIdwqKytVVlbmXZpAkhwOh4qKiuhOhyF4TxqLkZAW07GUvdR5KrHvsW8cEGqVlZUqKSlRenq6ysvLtXHjRpWXlys9PV0lJSWqrKw0OkVYDO9J49na+2C/fktLi2JjY9Xc3Myqst20ceNGPf3004qLi1NFRYU+/PBDb3f6VVddpSlTpsjpdKq4uFgTJkwwOl1YgMfj0bRp05Senh5wSmdxcbHq6+u1evVqLvcgLHhPhk53vr/pQbGYjp2gnU6nHn/8cb3++uvasGGDXn/9dT3++OPenhN2jEa4+C4rfvr09oiICJYVR9jxnjQHxqBYTFxcnCTpwgsvDLhg3sCBA3X8+HFvHBBqLCsOs+E9aQ70oFhMx/Th1tbWgO3Hjx/3iwNCzXdZ8UBYVhzhxnvSHChQLOZ73/ue936grstAcUAo+S4rfuLECa1du1ZLly7V2rVrdeLECZYVR9j5vidPnjyp3bt3a/Pmzdq9e7dOnjzJezJMGCRrMc8//7x3Q8cLLrhAJ0+e9Lb5Ht955536xS9+YUiOsJ7Kyko9/vjjZ2xfvHgx0zoRVh2zeKKiouRyubzn7Xa73G43q8n2EINkcUa7d+/23j9bD4pvHBBqe/fulXTm92RHOxBOZ/r93gd/1/dJDJK1mH79vvtfHhcXp6ioKH3xxRfettjYWLndbjmdTm8cEGput1sVFRUaNGiQ1q5d22nq+913362Kigrdf//9ioqKMjpdWIDH41FZWZkuv/xyffPNN50+JwcNGqTly5drzJgxTDMOIXpQLCYjI0PSd9OMAy1A1DHNuCMOCLX169fL4/Ho/vvvl91uV1ZWlvLy8pSVlSW73a7Zs2fL4/F0aZNLIBg6phnX1dXp0ksv9fucvPTSS1VXV8c04zDgZ7LFXH311dqwYYMkaefOnfrqq6/Uv39/nThxwm/E+tVXX21UirCYhoYGSdKNN94YsL3jfEccEGpffvmlJCk7O1uLFy9WbW2ttm3bpoSEBC1evFjFxcWqrq72xiE0KFAs5tixY977Ho9H+/btO2ccEEopKSmSpG3btik/P79T+7Zt2/zigFDr6El2OByaPn16p714Ro8e7ReH0OASj8V0dQE2FmpDuBQUFCgyMlK///3vderUKb+2U6dOacWKFYqMjFRBQYExCcJyOj7/3nzzTQ0fPlyTJ0/WnXfeqcmTJ2v48OHemZB8ToYWPSgW09Vp2UzfRrhERUVpypQpWrNmjSZNmqTZs2frxhtv1LZt27RixQp98803mjp1KgNkETa+C7AFWnE7UByCjwLFYt577z3v/YiICLW1tQU8fu+993TDDTeEPT9YU2FhoSRp7dq1ev75573nIyMjNXXqVG87EG5n+5xEaFGgWMznn3/uvR8ZGen3h+Z77BsHhENGRoaGDBmipqYm77nBgwczowxh5zv4dfTo0brhhhtkt9vlcrm0fft2b68Kg2RDiwLFYnxXRLTZbH5tvse+cUCodazamZOToyeffFJpaWmqr6/Xq6++qpKSElbtRFh9+OGHkqSbb75ZH3/8sd9lHofDoTFjxujdd9/Vhx9+qAkTJhiV5nmPQbIWM3z4cO/9QAMSA8UBodSxKFZOTo6efvppZWRkaODAgcrIyNDTTz+tnJwcLV++XB6Px+hUYREdP9YaGho6/ZCTpMOHD/vFITQoUCzGd4XYtrY2jRo1SsuWLdOoUaP8LvewkizCpWNRrJkzZwZc6n7GjBksioWwuvjiiyVJ+/fvl8vl0j333KN58+bpnnvukcvl0v79+/3iEBp8C1nMZZdd5ne8c+dO7dy585xxQKgcOXJEkpSWlhawPT093S8OCLX8/HwtW7ZMERERam5u1muvveZti4iI8A6UDbRuD4KHHhSL+fjjj4MaB/RWx1RN35WMfX366ad+cUCo/fOf/5T0XS/z6TN2fM91xCE0KFAAGCozM1MOh0OvvvpqwC+DlStXKjk5WZmZmQZlCKvp6uwcZvGEFgWKxSQnJwc1DuityMhIFRUVqaqqSsXFxaqtrdXx48dVW1ur4uJiVVVVqbCwkF1jETbffPONJCkpKUlDhgzxaxsyZIiSkpL84hAajEEBYLjc3FyVlpaqrKzMb1G25ORkphgj7JqbmyVJTU1Nys7OVm5urlwul+x2uw4dOqTq6mq/OIQGBYrF/Otf//Let9lsam9vD3jsGweEQ25ursaMGaOamhodOXJECQkJyszMpOcEhqqurvYWJAgvLvFYTMeAQ0l+xcnpx75xQLh4PB598sknqq2t1SeffMLaJzCE715kgaa+B4pD8NGDYjFd3XCNjdkQbsuXL1dFRYVfUVJeXq4pU6awFw/CyrfwCDRwO1Acgo8eFIsZMGCA3/Ho0aO1bNkyjR49+qxxQCgtX75ca9asUUxMjBYsWKB169ZpwYIFiomJ0Zo1a7R8+XKjU4SFdHX6MNOMQ4sCxWKys7O99202m3bs2KG5c+dqx44dfl2XvnFAKLndblVUVGjQoEFau3athg4dqt27d2vo0KFau3atBg0apIqKCrndbqNThUV0dbdidjUOrW4XKFu3blV+fr5SUlJks9m0fv16v/b29naVlJQoOTlZAwYMUF5enj755BO/mK+//lrTp09XTEyM4uLiNHv2bB07dqxXLwRd4zvY6/QxKL5/bAwKQ7isX79eHo9HY8eO1cyZM/Xwww+rtLRUDz/8sGbOnKmbb75ZHo+n02cNECpffPGF9/4FF1zg1+Z77BuH4Ot2gdLa2qqRI0eqrKwsYPuzzz6rF154QS+++KKqq6t14YUX6rbbbtOJEye8MdOnT9fevXu1adMmbdiwQVu3btUDDzzQ81eBLuvqLsXsZoxwaWhokCS99dZbSktL0+TJk3XnnXdq8uTJSktL05///Ge/OCDUzrSqcU/j0DPdHiQ7ceJETZw4MWBbe3u7li5dqscee0w//OEPJUn/9V//paSkJK1fv15Tp07VRx99pI0bN2rnzp26/vrrJUm//e1vdfvtt+v5559XSkpKL14OzmXo0KF6//33uxQHhIPD4ZAkxcbGqrq62q8nLyIiQjExMWpubvbGAaF28uTJgPfP1YbgCuoYlPr6ejU2NiovL897LjY2VtnZ2aqqqpIkVVVVKS4uzlucSFJeXp4iIiLOeFnB5XKppaXF74aeuemmm7z3T98q3PfYNw4IpY7NAJ1Op6Kjo/0GyUZHR3sXw+qIA0Ktq8UwRXNoBbVAaWxslCTvMsAdkpKSvG2NjY1KTEz0a+/Xr5/i4+O9MadbsmSJYmNjvbfU1NRgpm0pvkszn20dFJZwRrh8/fXX3vsRERFqb2/33nwHbvvGAaE0YcKEoMahZ/rELJ6FCxequbnZezt06JDRKfVZH374YVDjgN7qeK9deeWVamlp0fPPP6+77rpLzz//vFpaWnTFFVf4xQGh1tWFKlnQMrSCWqB0dHc1NTX5nW9qavK2ORyOTiOfT506pa+//vqM3WV2u10xMTF+N/RMV6+Zcm0V4dJxafGiiy7Shg0bVFBQoFGjRqmgoEAbNmzQRRdd5BcHhFpXVzBmpePQCupKsmlpaXI4HNqyZYuuvfZaSVJLS4uqq6v14IMPSpJycnLkdDq1a9cuXXfddZKkt99+W21tbay9EQZ79+4NahzQWxdffLEkaefOnSooKPDOINu5c6f+8pe/eI874oBQYxaPOXS7B+XYsWPas2eP9uzZI+m7/0F79uzRwYMHZbPZ9Mgjj+ipp57SW2+9pX/84x+69957lZKSooKCAknfdeNOmDBBc+bM0Y4dO/Tee+9p7ty5mjp1KjN4wsB3hsTpv0h9r/ezABHCpaCgoNN+J6eLiIjwfoYAoWa324Mah57pdg/K+++/r/Hjx3uP58+fL0maNWuWXnnlFf3yl79Ua2urHnjgATmdTo0ZM0YbN25U//79vf9m1apVmjt3rm655RZFRERo0qRJeuGFF4LwcnAuZxto6DtIlgGJCJfIyEj1799fx48f14ABA/TDH/5QF198sf71r3/pf//3f+VyudS/f392NUbYpKSkaNeuXV2KQ+h0u0AZN25cp9kfvmw2m0pLS1VaWnrGmPj4eK1evbq7T40gO9ssHiBcampqdPz4cf3gBz/Qli1btHbtWm9bRESE8vLytHnzZtXU1CgrK8vATAGEU5+YxYPgiYuLC2oc0FtHjhyR9N3+T6cvQZCYmKgbbrjBLw4Itc8//zyoceiZoA6Shfndeuut+sMf/tClOCAcEhISJEm//vWvlZOTo2nTpslut8vlcqm6ulq//vWv/eKAUOvqtgpsvxBaFCgWQw8KzCYjI8M7DmX//v3atm2bty0pKUkDBw7UiRMnlJGRYWCWsBLfMZPBiEPPcInHYt54442gxgG9tXfvXnk8HrW2tsrtdvstde92u9Xa2iqPx8PUd4RNV9fcYW2e0KIHxWKOHj0a1Digt7788ktJ0ve+9z01Nzfrueee87YlJSXpe9/7nj755BNvHBBqV111lT777LMuxSF06EGxmK5utMiGjAgXp9Mp6bsP+9PXQ7HZbLryyiv94oBQO3DgQFDj0DP0oFgMS93DbDrGO7355pu64YYbNGbMGLndbkVFRenzzz/XW2+95RcHhBqfk+ZAgWIx/fr106lTp7oUB4SD7+yc7du3dykOCKWBAwcGNQ49wyUeixk0aFBQ44BgOn3QIYMQYYSO/Z+CFYeeoUCxmK4uzcwSzggX38GvZ1vdmEGyCJdvv/02qHHoGQoUi2EbcZjNhx9+GNQ4AOcHChSLGTZsWFDjgN7yLYbj4+P92nyPKZoRLl2dPsw049CiQLEYps/BbOrr6733T59K7HvsGweEUnNzc1Dj0DMUKBbT1S3r2doe4RIVFeW9f/r7znc2mW8cEEqn9+T1Ng49Q4FiMY2NjUGNA3prwIAB3vunryvhdrsDxgGh1NUB2QzcDi0KFIs5duxYUOOA3kpNTQ1qHNBbdXV1QY1Dz1CgWAyXeGA2vCdhNqyDYg4UKBZz8cUXBzUO6K3W1tagxgG9ddFFFwU1Dj1DgWIxQ4cODWoc0FttbW1BjQN6KysrK6hx6BkKFIupqqoKahzQW0eOHAlqHNBb//rXv4Iah56hQLEYdumE2XR1l2J2M0a4dHVKO1PfQ4sCxWIoUGA2n376aVDjgN6iQDEHChSL4Xo/zIbudJgNlx3Nod+5QwAgdHx3LI6Li9O1116rAQMG6Ntvv9WePXu8y92fvtMxECpHjx4Nahx6hgIFgKHi4+O9H/TNzc165513vG0RERF+cUA4JCQkdGk17YSEhDBkY11c4rEYm80W1DigtzIzM733T+8l8b3U6BsHhNIPfvCDoMahZyhQLMZ387VgxAG9NWzYsKDGAb21c+fOoMahZyhQLGbIkCFBjQN667bbbgtqHNBb7FlmDhQoFtPU1BTUOKC3VqxYEdQ4oLcOHjwY1Dj0DAWKxXg8nqDGAb114MCBoMYBvcVyDOZAgQLAUJ9//rn3/ukzdXyPfeOAUGpubg5qHHqGkZAADOX7IX/ppZfqpptuUlRUlNxut9577z3t2LGjUxyA8x8FCgBD+U4t3rFjh7cgOVscgPNf0C/xDB8+XDabrdOtqKhIkjRu3LhObT/72c+CnQaAPsLhcAQ1DsD5IegFys6dO3X48GHvbdOmTZKkKVOmeGPmzJnjF/Pss88GOw0AfYTvZ0Mw4oDeuuCCC4Iah54J+iWe09fPeOaZZzRixAjl5uZ6zw0cOJBfQwAkSW63O6hxQG+x67s5hHQWj9vt1sqVK/WTn/zEb+n0VatWafDgwbr66qu1cOFCHT9+PJRpADCxiy66KKhxAM4PIR0ku379ejmdTt13333ecz/60Y80bNgwpaSkqKamRo8++qjq6ur0xhtvnPFxXC6XXC6X97ilpSWUaQMIo5qami7H3X777SHOBoBZhLRAWbFihSZOnKiUlBTvuQceeMB7/5prrlFycrJuueUW7d+/XyNGjAj4OEuWLNGiRYtCmSoAg3zwwQdBjQNwfgjZJZ4DBw5o8+bNuv/++88al52dLUnat2/fGWMWLlyo5uZm7+3QoUNBzRWAcXx7R4MRB+D8ELIelJdfflmJiYm64447zhq3Z88eSVJycvIZY+x2u+x2ezDTA2ASXV3fhHVQEC4RERFdWsY+IoLF2EMpJAVKW1ubXn75Zc2aNUv9+v3fU+zfv1+rV6/W7bffroSEBNXU1GjevHkaO3asMjMzQ5EKAJOLjo6W0+nsUhwQDrGxsfrmm2+6FIfQCUmBsnnzZh08eFA/+clP/M5HRUVp8+bNWrp0qVpbW5WamqpJkybpscceC0UaAPoAphnDbL799tugxqFnQlKg3HrrrQG7Y1NTU1VZWRmKpwTQRyUlJampqalLcUA4DBgwQCdOnOhSHEKHC2gADNWV4qQ7cUBvsVCbOVCgADAUy4rDbGJiYoIah56hQAFgKHpQYDYNDQ1BjUPPUKAAMBTd6QACoUABAACmQ4ECwFBdXYSRxRoBa6FAAWCoqKiooMYBOD9QoAAw1PHjx4MaB+D8QIECwFBd3c+EfU8Aa+EvHoChmMUDIBAKFAAAYDoUKAAAwHRCslkguubEiRM6cOCA0WmcUV1dXVifb9iwYerfv39YnxMAYE4UKAY6cOCA5syZY3QaZxTu3F566SVdfvnlYX1OAIA5UaAYaNiwYXrppZfC/rxdKTyMyGvYsGFhf04AgDlRoBiof//+hvQYbN26Vbm5uWpvb+/UZrPZVFlZGfacAADwRYFiUZWVlfrss8/04x//WB6PR5GRkXr55Zc1fPhwo1MDAC8jxurZbLaAP+ACxTFWL3QoUCxs+PDhevHFFzVnzhy9+OKLFCcATMfMY/Xa29sZqxdCFCgAANNirJ4/K43Vo0AB4MXUd39W6k43KyPH6o0dO/as7QgtChQAXmbuTpeY+o7w2rp1q/bt26fZs2ervb1dNptNK1as0KWXXmp0apZAgQLAy4ju9I8//ljPPffcOeMWLFigyy67LAwZ/R8rdacjsEsvvVS/+93vNGfOHP3ud7+jOAkjChQAXkZ0p19++eVdKlDy8/PDkA0As2AvHgCGO9f1fK73A9ZDgQLAFLZu3aply5b5nVu2bBnFCWBRFCgATCMzM9M7Buall15SZmamwRkBMAoFCgAAMB0KFAAAYDoUKAAAwHQoUAAAgOlQoAAAANOhQAEAAKZDgQIAAEyHAgUAAJhO0AuUJ598Ujabze92xRVXeNtPnDihoqIiJSQk6KKLLtKkSZPU1NQU7DQAAEAfFpIelIyMDB0+fNh7e/fdd71t8+bN05///GdVVFSosrJSDQ0Nuuuuu0KRBgAA6KNCsptxv3795HA4Op1vbm7WihUrtHr1av3bv/2bJOnll1/WlVdeqe3bt+uGG24IRToAAKCPCUkPyieffKKUlBSlp6dr+vTpOnjwoCRp165dOnnypPLy8ryxV1xxhS655BJVVVWd8fFcLpdaWlr8bgAA4PwV9AIlOztbr7zyijZu3Kjy8nLV19fr5ptv1tGjR9XY2KioqCjFxcX5/ZukpCQ1Njae8TGXLFmi2NhY7y01NTXYaQMAABMJ+iWeiRMneu9nZmYqOztbw4YN09q1azVgwIAePebChQs1f/5873FLSwtFCgAA57GQTzOOi4vTZZddpn379snhcMjtdsvpdPrFNDU1BRyz0sFutysmJsbvBgAAzl8hL1COHTum/fv3Kzk5Wdddd50uuOACbdmyxdteV1engwcPKicnJ9SpAACAPiLol3h+8YtfKD8/X8OGDVNDQ4OeeOIJRUZGatq0aYqNjdXs2bM1f/58xcfHKyYmRg899JBycnKYwQMAALyCXqB8/vnnmjZtmo4cOaIhQ4ZozJgx2r59u4YMGSJJ+s///E9FRERo0qRJcrlcuu2227R8+fJgpwEAAPqwoBcoa9asOWt7//79VVZWprKysmA/NQAAOE+wFw8AADAdChQAAGA6FCgAAMB0KFAAAIDpUKAAAADToUABAACmQ4ECAABMhwIFAACYDgUKAAAwHQoUAABgOhQoAADAdChQAACA6VCgAAAA06FAAQAApkOBAgAATIcCBQAAmA4FCgAAMB0KFAAAYDoUKAAAwHT6GZ0AgP/T1NQkp9NpdBqGOnDggN9/rSwuLk5JSUlGpwEYggIFMImmpibNmD5dLrfb6FRM4amnnjI6BcPZo6K0ctUqihRYEgUKYBJOp1Mut1sPZrQq5UKP0enAYA2tkSrf+937wsgChV49evVOF66ePUsXKPzh8Yfnyyzd6SkXepQWQ4EC4zU1NWn6jOlyu+jVk+jV6xBlj9KqlaHv2bNsgdLU1KTp02fI7XYZnYop8IcnRUXZtWrVSlMUKYAZOJ1OuV1utY1uU3tMu9HpwARsLTa5d7jD0rNn2QLF6XTK7XbpxIhxah8QZ3Q6MJjtW6e0/x3Du9MBM2qPaZcGGZ0FzKBd4StULVugdGgfEKe2CwcbnQYMxnx7ADAXPpcBAIDpUKAAAADToUABAACmQ4ECAABMhwIFAACYDgUKAAAwHQoUAABgOkEvUJYsWaJRo0YpOjpaiYmJKigoUF1dnV/MuHHjZLPZ/G4/+9nPgp0KAADoo4JeoFRWVqqoqEjbt2/Xpk2bdPLkSd16661qbW31i5szZ44OHz7svT377LPBTgUAAPRRQV9JduPGjX7Hr7zyihITE7Vr1y6NHTvWe37gwIFyOBzBfnqgz2to5coreB8AIV/qvrm5WZIUHx/vd37VqlVauXKlHA6H8vPz9fjjj2vgwIGhTgcwvfK9FxmdAgAYLqQFSltbmx555BHddNNNuvrqq73nf/SjH2nYsGFKSUlRTU2NHn30UdXV1emNN94I+Dgul0su1//tOtzS0hLKtAFDPZhxTCkXthmdBgzW0BpBsQpLC2mBUlRUpNraWr377rt+5x944AHv/WuuuUbJycm65ZZbtH//fo0YMaLT4yxZskSLFi0KZaqAaaRc2Ka0GI/RaQCAoUJ2kXPu3LnasGGD/va3v2no0KFnjc3OzpYk7du3L2D7woUL1dzc7L0dOnQo6PkCAADzCHoPSnt7ux566CGtW7dO77zzjtLS0s75b/bs2SNJSk5ODthut9tlt9uDmSYAoKu4qo4OYXwvBL1AKSoq0urVq/Xmm28qOjpajY2NkqTY2FgNGDBA+/fv1+rVq3X77bcrISFBNTU1mjdvnsaOHavMzMxgpwMA6KXIHZFGpwALCnqBUl5eLum7xdh8vfzyy7rvvvsUFRWlzZs3a+nSpWptbVVqaqomTZqkxx57LNipAACCwDPaI8UYnQVMoSV8BWtILvGcTWpqqiorK4P9tACAUImRNMjoJGA1IV8Hxexs3zrZkAiyfes0OgUAgA/LFyj9979jdAoAAOA0li9QTowYp/YBcUanAYPZvnVSrAKAiVi+QGkfEKe2CwcbnQYMxmU+ADAXPpcBAIDpWL4HBTCbhlbWnADvA4ACBTCJuLg42aOiVL7X6ExgFvaoKMXFxRmdBmAIChTAJJKSkrRy1So5nU6jUzHUgQMH9NRTT+mxxx7TsGHDjE7HUHFxcUpKSjI6DcAQFCiAiSQlJfGF9P8bNmyYLr/8cqPTAGAQBskCAADToQcFAHBWthab2nX2bUxgDbYWW9ieiwIFABBQXFycouxRcu9wG50KTCTKHp7B2xQoAICAkpKStGolA7cZuO0vXIO3KVAAAGfEwO3/w8Dt8GKQLAAAMB0KFAAAYDqWv8Rj+9ZJlQbZvnUanQIAwIdlC5S4uDhFRdml/e8YnQpMIirKzrLiAGASli1QkpKStGrVSkanMzrdi2XFAcA8LFugSIxO98XodACAmTD8AgAAmA4FCgAAMB0KFAAAYDoUKAAAwHQoUAAAgOlQoAAAANOhQAEAAKZDgQIAAEyHAgUAAJgOBQoAADAdSy91D8DfiRMndODAAUNz6Hh+o/OQvtsCon///kanAVgSBQoArwMHDmjOnDlGpyFJeuqpp4xOQS+99BJ7VAEGoUAB4DVs2DC99NJLRqdhGlbf4RswEgWKgehO90d3uvH69+9PjwFMhc9Jf1b6nLS1t7e3G/XkZWVleu6559TY2KiRI0fqt7/9rUaPHn3Of9fS0qLY2Fg1NzcrJiYmDJmGRl1dnWm6082A7nQAp+Nz0l9f/5zszve3YQXKa6+9pnvvvVcvvviisrOztXTpUlVUVKiurk6JiYln/bfnS4Fihl8GZmKlXwYAuobPSX99/XOyTxQo2dnZGjVqlJYtWyZJamtrU2pqqh566CH96le/Ouu/PV8KFAAArKQ739+GrIPidru1a9cu5eXl/V8iERHKy8tTVVVVp3iXy6WWlha/GwAAOH8ZUqB89dVX8ng8SkpK8juflJSkxsbGTvFLlixRbGys95aamhquVAEAgAH6xEqyCxcuVHNzs/d26NAho1MCAAAhZMg048GDBysyMlJNTU1+55uamuRwODrF2+122e32cKUHAAAMZkgPSlRUlK677jpt2bLFe66trU1btmxRTk6OESkBAAATMWyhtvnz52vWrFm6/vrrNXr0aC1dulStra368Y9/bFRKAADAJAwrUO655x59+eWXKikpUWNjo6699lpt3Lix08BZAABgPYauJNtTrIMCAEDfY/p1UAAAAM6GAgUAAJgOBQoAADAdChQAAGA6FCgAAMB0DJtm3BsdE4/YNBAAgL6j43u7KxOI+2SBcvToUUli00AAAPqgo0ePKjY29qwxfXIdlLa2NjU0NCg6Olo2m83odPq0lpYWpaam6tChQ6wpA1PgPQmz4T0ZPO3t7Tp69KhSUlIUEXH2USZ9sgclIiJCQ4cONTqN80pMTAx/eDAV3pMwG96TwXGunpMODJIFAACmQ4ECAABMhwLF4ux2u5544gnZ7XajUwEk8Z6E+fCeNEafHCQLAADOb/SgAAAA06FAAQAApkOBAgAATIcCBQAAmA4FioWVlZVp+PDh6t+/v7Kzs7Vjxw6jU4KFbd26Vfn5+UpJSZHNZtP69euNTgkWt2TJEo0aNUrR0dFKTExUQUGB6urqjE7LMihQLOq1117T/Pnz9cQTT+iDDz7QyJEjddttt+mLL74wOjVYVGtrq0aOHKmysjKjUwEkSZWVlSoqKtL27du1adMmnTx5UrfeeqtaW1uNTs0SmGZsUdnZ2Ro1apSWLVsm6bv9jVJTU/XQQw/pV7/6lcHZwepsNpvWrVungoICo1MBvL788kslJiaqsrJSY8eONTqd8x49KBbkdru1a9cu5eXlec9FREQoLy9PVVVVBmYGAObV3NwsSYqPjzc4E2ugQLGgr776Sh6PR0lJSX7nk5KS1NjYaFBWAGBebW1teuSRR3TTTTfp6quvNjodS+iTuxkDABBORUVFqq2t1bvvvmt0KpZBgWJBgwcPVmRkpJqamvzONzU1yeFwGJQVAJjT3LlztWHDBm3dulVDhw41Oh3L4BKPBUVFRem6667Tli1bvOfa2tq0ZcsW5eTkGJgZAJhHe3u75s6dq3Xr1untt99WWlqa0SlZCj0oFjV//nzNmjVL119/vUaPHq2lS5eqtbVVP/7xj41ODRZ17Ngx7du3z3tcX1+vPXv2KD4+XpdccomBmcGqioqKtHr1ar355puKjo72jtGLjY3VgAEDDM7u/Mc0YwtbtmyZnnvuOTU2Nuraa6/VCy+8oOzsbKPTgkW98847Gj9+fKfzs2bN0iuvvBL+hGB5Npst4PmXX35Z9913X3iTsSAKFAAAYDqMQQEAAKZDgQIAAEyHAgUAAJgOBQoAADAdChQAAGA6FCgAAMB0KFAAAIDpUKAAAADToUABAACmQ4ECAABMhwIFAACYDgUKAAAwnf8P00KqL5U0/1kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: rename below variable\n",
    "word_list = []\n",
    "for i, author in enumerate(author_names):\n",
    "    word_list.append(authors_df_list[i][f\"{author}_text_length\"].values)\n",
    "_ = sns.boxplot(data=word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3d0c1",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491b8a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19572, 25023)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def bag_of_words(df) :\n",
    "    labels = df[\"author\"]\n",
    "    df = df.drop(columns=[\"id\", \"author\"])\n",
    "\n",
    "    # Remove punctuation\n",
    "    to_remove = ['.', ',', '?', '!', ':', ';']\n",
    "    replacement = \" \"\n",
    "\n",
    "    pattern = \"|\".join(map(re.escape, to_remove))\n",
    "    df[\"text\"] = df[\"text\"].str.replace(pattern, replacement, regex=True)\n",
    "\n",
    "    # Tokenization\n",
    "    vectorizer = CountVectorizer(lowercase=True, binary=True) # Binary makes values 0/1\n",
    "    X = vectorizer.fit_transform(df[\"text\"])\n",
    "    print(X.shape)\n",
    "\n",
    "    return X, labels\n",
    "\n",
    "csr_matrix, labels = bag_of_words(df)\n",
    "labelEncoder = OneHotEncoder(sparse_output=False)\n",
    "labels = labelEncoder.fit_transform(pd.DataFrame(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aad9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUGAN\\AppData\\Local\\Temp\\ipykernel_32428\\2191032978.py:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  X = torch.sparse_coo_tensor(csr_matrix.nonzero(), np.array(csr_matrix.data), csr_matrix.shape, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "# 70-20-10 split\n",
    "train_val_test_split = [0.7, 0.2, 0.1]\n",
    "\n",
    "X = torch.sparse_coo_tensor(csr_matrix.nonzero(), np.array(csr_matrix.data), csr_matrix.shape, dtype=torch.double)\n",
    "y = torch.tensor(labels, device=device)\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "train_dataloader, val_dataloader, test_dataloader = random_split(dataset, train_val_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c7639",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0b8300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [01:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(epochs):\n\u001b[0;32m     52\u001b[0m     train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmini_batch(train\u001b[38;5;241m=\u001b[39mtrain, dataloader\u001b[38;5;241m=\u001b[39mval_dataloader, optimizer\u001b[38;5;241m=\u001b[39moptimizer, criterion\u001b[38;5;241m=\u001b[39mcriterion)\n",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m, in \u001b[0;36mLinearModel.mini_batch\u001b[1;34m(self, train, dataloader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     26\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(y_batch, outputs)\n\u001b[0;32m     28\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 29\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m         running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\code\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    513\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    514\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m             )\n\u001b[1;32m--> 517\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    520\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\code\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 82\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\code\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    235\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    237\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    238\u001b[0m         group,\n\u001b[0;32m    239\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m         state_steps,\n\u001b[0;32m    245\u001b[0m     )\n\u001b[1;32m--> 247\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\code\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\code\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    951\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 953\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\code\\Lib\\site-packages\\torch\\optim\\adam.py:447\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m    444\u001b[0m     device_beta1 \u001b[38;5;241m=\u001b[39m beta1\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m differentiable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta2, Tensor):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(25023, 16, dtype=torch.double)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(16, 3, dtype=torch.double)\n",
    "        self.softmax = nn.Softmax(0)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def mini_batch(self, train: bool, dataloader : DataLoader, optimizer: optim.Optimizer, criterion: nn.modules.loss._Loss) -> float:\n",
    "        running_loss = 0\n",
    "        if(train):\n",
    "            self.train(True)\n",
    "            for X_batch, y_batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(X_batch)\n",
    "                loss = criterion(y_batch, outputs)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "        else:\n",
    "            self.train(False)\n",
    "            for X_batch, y_batch in dataloader:\n",
    "                outputs = self.forward(X_batch)\n",
    "                loss = criterion(y_batch, outputs)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "        average_loss = running_loss/len(dataloader)\n",
    "        return average_loss\n",
    "\n",
    "# Create an instance of the network\n",
    "model = LinearModel()\n",
    "model = model.to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epochs = range(1, num_epochs+1)\n",
    "for epoch in tqdm(epochs):\n",
    "    train = True\n",
    "    train_loss = model.mini_batch(train=train, dataloader=train_dataloader, optimizer=optimizer, criterion=criterion)\n",
    "    train = False\n",
    "    val_loss = model.mini_batch(train=train, dataloader=val_dataloader, optimizer=optimizer, criterion=criterion)\n",
    "    print(f\"The training loss was: {train_loss} and the validation loss was: {val_loss}.\")\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f599587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(epochs, train_loss, color='b', label=\"Train Loss\")\n",
    "_ = plt.plot(epochs, val_loss, color='r', label=\"Val Loss\")\n",
    "_ = plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
